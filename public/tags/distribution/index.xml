<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Distribution on Leo&#39;s sharing space</title>
        <link>https://example.org/tags/distribution/</link>
        <description>Recent content in Distribution on Leo&#39;s sharing space</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Wed, 14 May 2025 15:10:48 +0800</lastBuildDate><atom:link href="https://example.org/tags/distribution/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Beta distribution</title>
        <link>https://example.org/post/beta_distribution/</link>
        <pubDate>Wed, 14 May 2025 15:10:48 +0800</pubDate>
        
        <guid>https://example.org/post/beta_distribution/</guid>
        <description>&lt;img src="https://example.org/post/beta_distribution/logcabin.jpg" alt="Featured image of post Beta distribution" /&gt;&lt;h2 id=&#34;beta-distribution&#34;&gt;Beta distribution
&lt;/h2&gt;&lt;p&gt;The Beta distribution is a continuous distribution on the interval (0,1). It is a generalization of the Unif(0,1) distribution.&lt;/p&gt;
&lt;p&gt;An random variable $X$ is said to have the Beta distribution with parameters $a$ and $b$, where $a,b &amp;gt; 0$, if its probability density function (PDF) is:&lt;/p&gt;
&lt;p&gt;$$f(x)=\frac{1}{\beta(a,b)}x^{a-1}(1-x)^{b-1},\quad0&amp;lt;x&amp;lt;1$$&lt;/p&gt;
&lt;p&gt;$\beta(a,b)$ is the beta function. It is a constant that chosen to make the PDF integrate to 1. We write this as $X \sim \text{Beta}(a,b)$.&lt;/p&gt;
&lt;p&gt;Taking $a=b=1$, the $Beta(1,1)$ PDF is $f(x)=1$, which is same as the uniform distribution $Unif(0,1)$, the proof is shown below.&lt;/p&gt;
&lt;h2 id=&#34;beta-function&#34;&gt;Beta function
&lt;/h2&gt;&lt;p&gt;To make the PDF of Beta distribution integrate to 1. The constant $\beta(a,b)$ is defined as:&lt;/p&gt;
&lt;p&gt;$$\beta(a,b)=\int_0^1 x^{a-1}(1-x)^{b-1}dx=\frac{(a-1)!(b-1)!}{(a+b-1)!}$$&lt;/p&gt;
&lt;p&gt;$Proof.$
Let&amp;rsquo;s use the induction to prove the above equation.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Base Case:&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For $b=1$:
$$\beta(a,1)=\int_0^1x^{a-1}dx=\frac{1}{a}=\frac{(a-1)!(1-1)!}{(a+1-1)!}$$&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;Recurrence Relation of the Beta Function:&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Using integration by parts on $\beta(a,b)$:
$$\beta(a,b+1)=\frac{b}{a+b}\beta(a,b)$$&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;Inductive Step:&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let&amp;rsquo;s assume the formula holds for $b=k$, i.e., $\beta(a,k)=\frac{(a-1)!(k-1)!}{(a+k-1)!}$.&lt;/p&gt;
&lt;p&gt;Then we have:
$$\beta(a,k+1)=\int_0^1 x^{a-1}(1-x)^{k}dx=\int_0^1 x^{a-1}(1-x)^{k}dx$$
As shown in 2, we can write:
$$\beta(a,k+1)=\frac{k}{a+k}\int_0^1 x^{a-1}(1-x)^{k-1}dx$$
$$=\frac{k}{a+k}\cdot\frac{(a-1)!(k-1)!}{(a+k-1)!}$$
$$=\frac{(a-1)!(k)!}{(a+k)!}$$
Thus, we have shown that if the formula holds for $b=k$, it also holds for $b=k+1$.&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;Conclusion:&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;By the principle of mathematical induction, the formula holds for all positive integers $b$. Symmetrically, we can also show that the formula holds for $a$ by using the same induction process.&lt;/p&gt;
&lt;h2 id=&#34;beta-binomial-conjugacy&#34;&gt;Beta-Binomial conjugacy
&lt;/h2&gt;&lt;p&gt;The Beta distribution is the conjugate prior of the Binomial distribution. This means that if we have a Binomial likelihood and a Beta prior, the posterior distribution will also be a Beta distribution.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s say we have a coin that we want to test for bias. We flip the coin $n$ times and observe $k$ heads. We can model this with a Binomial distribution, where the probability of heads is $p$. The likelihood function is given by:
$$P(X=k|p)=\binom{n}{k}p^k(1-p)^{n-k}$$
where $X$ is the number of heads observed in $n$ flips.
The likelihood function is a function of $p$, and it tells us how likely we are to observe $k$ heads given a particular value of $p$.&lt;/p&gt;
&lt;p&gt;For example, if we have a Binomial likelihood with parameters $n$ and $k$, and a Beta prior with parameters $a$ and $b$, the posterior distribution will be:&lt;/p&gt;
&lt;p&gt;$$f(p|X=k)=\frac{P(X=k|p)f(p)}{P(X=k)}=\frac{(_k^n)p^k(1-p)^{n-k}\cdot\frac{1}{\beta(a,b)}p^{a-1}(1-p)^{b-1}}{P(X=k)}$$
$$=\frac{(_k^n)p^k(1-p)^{n-k}\cdot\frac{1}{\beta(a,b)}p^{a-1}(1-p)^{b-1}}{\int_0^1P(X=k|p)f(p)dp}$$&lt;/p&gt;
&lt;p&gt;It is difficult to calculate the denominator. Are we stucked here?&lt;/p&gt;
&lt;p&gt;Acutally, the calculation is much easier than it appears. The conditional PDF $f(p|X=k)$ is a function of $p$, which means everthing that desn&amp;rsquo;t depend on $p$ is a constant. We can drop all these constants and find the PDF up to a multiplicative constant (and then the normalizing constant is whatever it needs to make the PDF integrate to 1). We can drop the $(_k^n)$, $\frac{1}{\beta(a,b)},$ and the denominator $P(X=k)$. So we can write:&lt;/p&gt;
&lt;p&gt;$$f(p|X=k)\propto p^{k+a-1}(1-p)^{n-k+b-1}$$&lt;/p&gt;
&lt;p&gt;Which is very close to the PDF of a Beta distribution $Beta(a+k, b+n-k)$, up to a multiplicative constant. Therefore, we can conclude that the posterior distribution is:&lt;/p&gt;
&lt;p&gt;$$f(p|X=k)\sim Beta(a+k, b+n-k)$$&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
